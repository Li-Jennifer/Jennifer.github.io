(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{348:function(a,s,t){a.exports=t.p+"assets/img/ml_loss.dceb908d.png"},349:function(a,s,t){a.exports=t.p+"assets/img/ml_squared.bd88872d.png"},350:function(a,s,t){a.exports=t.p+"assets/img/ml_average.25950e00.png"},351:function(a,s,t){a.exports=t.p+"assets/img/ml_argmin.eae84a23.png"},352:function(a,s,t){a.exports=t.p+"assets/img/ml_gradient.d9570ee1.png"},353:function(a,s,t){a.exports=t.p+"assets/img/ml_gradient_descent.a9809bc8.png"},354:function(a,s,t){a.exports=t.p+"assets/img/ml_supplementary.90cd1db2.png"},355:function(a,s,t){a.exports=t.p+"assets/img/ml_ployn.4150ae80.png"},356:function(a,s,t){a.exports=t.p+"assets/img/ml_ploynomial.4cc63ee8.png"},357:function(a,s,t){a.exports=t.p+"assets/img/ml_minimizing.e5484e29.png"},358:function(a,s,t){a.exports=t.p+"assets/img/ml_general_linear.2a2b1ac5.png"},359:function(a,s,t){a.exports=t.p+"assets/img/ml_loocv.abad3ea3.png"},360:function(a,s,t){a.exports=t.p+"assets/img/ml_basic_function.b7c5eb59.png"},361:function(a,s,t){a.exports=t.p+"assets/img/ml_function_graph.0be387ae.png"},362:function(a,s,t){a.exports=t.p+"assets/img/ml_bayes.0722c837.png"},363:function(a,s,t){a.exports=t.p+"assets/img/ml_bayes_compute.8a01a18f.png"},364:function(a,s,t){a.exports=t.p+"assets/img/ml_bayes_likelihood.f1e37446.png"},517:function(a,s,t){"use strict";t.r(s);var r=t(6),e=Object(r.a)({},(function(){var a=this,s=a._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h2",{attrs:{id:"regression-回归"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#regression-回归"}},[a._v("#")]),a._v(" Regression(回归)")]),a._v(" "),s("h2",{attrs:{id:"_1-linear-regression-线性回归"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-linear-regression-线性回归"}},[a._v("#")]),a._v(" 1. Linear regression（线性回归）")]),a._v(" "),s("h3",{attrs:{id:"_1-1variables"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-1variables"}},[a._v("#")]),a._v(" 1.1Variables")]),a._v(" "),s("p",[a._v("Olympic : X")]),a._v(" "),s("p",[a._v("Winning time: Y")]),a._v(" "),s("h3",{attrs:{id:"_1-2modle"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-2modle"}},[a._v("#")]),a._v(" 1.2Modle")]),a._v(" "),s("p",[a._v("t = f(x)")]),a._v(" "),s("h3",{attrs:{id:"_1-3data-training-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-3data-training-data"}},[a._v("#")]),a._v(" 1.3Data (training data)")]),a._v(" "),s("ul",[s("li",[a._v("N attribute-response pairs, (Xn, tn)")]),a._v(" "),s("li",[a._v("e.g. (1896,12s), (1900, 11s), . .., (2008, 9.69s)")]),a._v(" "),s("li",[a._v("X1 = 1896, t1 = 12, etc")])]),a._v(" "),s("h3",{attrs:{id:"_1-4-linear-model"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-linear-model"}},[a._v("#")]),a._v(" 1.4 Linear Model")]),a._v(" "),s("p",[a._v("t = f (x) = w0 + w1x = f(x;,w0,w1)")]),a._v(" "),s("h4",{attrs:{id:"a-w-0-w-1-best"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#a-w-0-w-1-best"}},[a._v("#")]),a._v(" a. W_0, W_1 (best)")]),a._v(" "),s("h4",{attrs:{id:"b-loss-function"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#b-loss-function"}},[a._v("#")]),a._v(" b.Loss function")]),a._v(" "),s("p",[s("img",{attrs:{src:t(348),alt:""}})]),a._v(" "),s("h4",{attrs:{id:"c-squared-loss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#c-squared-loss"}},[a._v("#")]),a._v(" c. Squared Loss")]),a._v(" "),s("p",[s("img",{attrs:{src:t(349),alt:""}})]),a._v(" "),s("h4",{attrs:{id:"e-average-squared-loss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#e-average-squared-loss"}},[a._v("#")]),a._v(" e.Average Squared loss")]),a._v(" "),s("p",[s("img",{attrs:{src:t(350),alt:""}})]),a._v(" "),s("h4",{attrs:{id:"f-argmin-l"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#f-argmin-l"}},[a._v("#")]),a._v(" f. argmin L")]),a._v(" "),s("p",[s("img",{attrs:{src:t(351),alt:""}})]),a._v(" "),s("h4",{attrs:{id:"g-gradient-descent-梯度下降"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#g-gradient-descent-梯度下降"}},[a._v("#")]),a._v(" g.Gradient Descent(梯度下降)")]),a._v(" "),s("p",[s("img",{attrs:{src:t(352),alt:""}}),a._v(" "),s("img",{attrs:{src:t(353),alt:""}})]),a._v(" "),s("h4",{attrs:{id:"h-supplementary"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#h-supplementary"}},[a._v("#")]),a._v(" h.supplementary")]),a._v(" "),s("p",[s("img",{attrs:{src:t(354),alt:""}})]),a._v(" "),s("h2",{attrs:{id:"_2-polynomial-regression-多项式回归"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-polynomial-regression-多项式回归"}},[a._v("#")]),a._v(" 2.Polynomial regression(多项式回归)")]),a._v(" "),s("h3",{attrs:{id:"_2-1-polynomial"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-polynomial"}},[a._v("#")]),a._v(" 2.1 Polynomial")]),a._v(" "),s("p",[s("img",{attrs:{src:t(355),alt:""}})]),a._v(" "),s("h3",{attrs:{id:"_2-2-vector-form-still-a-linear-regression"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-vector-form-still-a-linear-regression"}},[a._v("#")]),a._v(" 2.2 Vector form (still a linear regression)")]),a._v(" "),s("p",[s("img",{attrs:{src:t(356),alt:""}})]),a._v(" "),s("h3",{attrs:{id:"_2-3-minimizing-the-loss"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-minimizing-the-loss"}},[a._v("#")]),a._v(" 2.3 Minimizing the loss")]),a._v(" "),s("p",[s("img",{attrs:{src:t(357),alt:""}})]),a._v(" "),s("h3",{attrs:{id:"_2-4-general-linear-regression"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-general-linear-regression"}},[a._v("#")]),a._v(" 2.4 General Linear Regression")]),a._v(" "),s("p",[s("img",{attrs:{src:t(358),alt:""}})]),a._v(" "),s("h3",{attrs:{id:"_2-5-generalization-and-over-fitting-泛化和过度学习"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-generalization-and-over-fitting-泛化和过度学习"}},[a._v("#")]),a._v(" 2.5 Generalization and over-fitting   泛化和过度学习")]),a._v(" "),s("p",[a._v("Nosie :噪音")]),a._v(" "),s("h3",{attrs:{id:"_2-6-cross-validation-cv-交叉验证"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-cross-validation-cv-交叉验证"}},[a._v("#")]),a._v(" 2.6 Cross-validation(CV) 交叉验证")]),a._v(" "),s("p",[a._v("repeat to make results more accurate")]),a._v(" "),s("ol",[s("li",[a._v("5-fold CV")]),a._v(" "),s("li",[a._v("10-fold CV")]),a._v(" "),s("li",[a._v("Leave-one-out CV (LOOCV) 留一法\n"),s("img",{attrs:{src:t(359),alt:""}})])]),a._v(" "),s("h3",{attrs:{id:"_2-5-common-function"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-common-function"}},[a._v("#")]),a._v(" 2.5 Common function")]),a._v(" "),s("p",[s("img",{attrs:{src:t(360),alt:""}}),a._v(" "),s("img",{attrs:{src:t(361),alt:""}})]),a._v(" "),s("h2",{attrs:{id:"_3-bayesian-linear-regression-贝叶斯线性回归"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-bayesian-linear-regression-贝叶斯线性回归"}},[a._v("#")]),a._v(" 3.Bayesian linear regression (贝叶斯线性回归)")]),a._v(" "),s("h3",{attrs:{id:"_3-1-bayes-rule"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-bayes-rule"}},[a._v("#")]),a._v(" 3.1 Bayes rule")]),a._v(" "),s("p",[s("img",{attrs:{src:t(362),alt:""}})]),a._v(" "),s("h3",{attrs:{id:"_3-2-compute"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-compute"}},[a._v("#")]),a._v(" 3.2 compute")]),a._v(" "),s("p",[s("img",{attrs:{src:t(363),alt:""}})]),a._v(" "),s("h3",{attrs:{id:"_3-3-likelihood-posterior-and-data-可能性-后验和数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-likelihood-posterior-and-data-可能性-后验和数据"}},[a._v("#")]),a._v(" 3.3 likelihood, posterior, and data (可能性，后验和数据)")]),a._v(" "),s("p",[s("img",{attrs:{src:t(364),alt:""}})])])}),[],!1,null,null,null);s.default=e.exports}}]);