(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{399:function(e,a,t){e.exports=t.p+"assets/img/ml_explainable_model.e1ce98d0.png"},400:function(e,a,t){e.exports=t.p+"assets/img/ml_decision_tree.f36474fd.png"},401:function(e,a,t){e.exports=t.p+"assets/img/ml_inter_explain.da7b7fa2.png"},402:function(e,a,t){e.exports=t.p+"assets/img/ml_inter_expl_2.cd8da8d1.png"},523:function(e,a,t){"use strict";t.r(a);var i=t(6),n=Object(i.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"_1-explainable-machine-learning-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-explainable-machine-learning-model"}},[e._v("#")]),e._v(" 1.Explainable Machine Learning Model")]),e._v(" "),a("h3",{attrs:{id:"_1-1-explainable-model-representation-learning-可解释模型-表示学习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-explainable-model-representation-learning-可解释模型-表示学习"}},[e._v("#")]),e._v(" 1. 1 Explainable Model – Representation Learning  可解释模型-表示学习")]),e._v(" "),a("ul",[a("li",[e._v("Knowledge of the what each node represents")]),e._v(" "),a("li",[e._v("Latent factors that affect the decision process")]),e._v(" "),a("li",[e._v("How important each node is to the model’s performance\n"),a("img",{attrs:{src:t(399),alt:""}})])]),e._v(" "),a("h3",{attrs:{id:"_1-2-interpretable-model-decision-trees-可解释模型-决策树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-interpretable-model-decision-trees-可解释模型-决策树"}},[e._v("#")]),e._v(" 1.2 Interpretable Model -Decision Trees  可解释模型- 决策树")]),e._v(" "),a("ul",[a("li",[e._v("It is clearly what each node represents")]),e._v(" "),a("li",[e._v("Easy to visualize and overview the whole decision operation")]),e._v(" "),a("li",[e._v("Easy to explain to non-specialists")]),e._v(" "),a("li",[e._v("Results can be tracked and associated with the output of each node\n"),a("img",{attrs:{src:t(400),alt:""}})])]),e._v(" "),a("h3",{attrs:{id:"_1-3-interpretable-vs-explainable-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-interpretable-vs-explainable-models"}},[e._v("#")]),e._v(" 1.3 Interpretable vs Explainable Models")]),e._v(" "),a("p",[a("img",{attrs:{src:t(401),alt:""}}),a("img",{attrs:{src:t(402),alt:""}})]),e._v(" "),a("h3",{attrs:{id:"reference"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reference"}},[e._v("#")]),e._v(" reference")]),e._v(" "),a("ul",[a("li",[e._v("Arrieta et al. ‘Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI’, Information Fusion, 2020.")]),e._v(" "),a("li",[e._v("Molnar ‘Interpretable Machine Learning - A Guide for Making Black Box Models Explainable’ https://christophm.github.io/interpretable-ml-book/")])]),e._v(" "),a("h2",{attrs:{id:"_2-feature-ranking-as-model-agnostic-explanations-permutation-feature-importance-特征排序作为模型不可知的解释-排列特征重要性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-feature-ranking-as-model-agnostic-explanations-permutation-feature-importance-特征排序作为模型不可知的解释-排列特征重要性"}},[e._v("#")]),e._v(" 2.Feature Ranking as Model Agnostic Explanations: Permutation Feature Importance 特征排序作为模型不可知的解释:排列特征重要性")]),e._v(" "),a("p",[e._v("Taxonomy")]),e._v(" "),a("ul",[a("li",[e._v("Local vs Global Explanations")]),e._v(" "),a("li",[e._v("Model Agnostic vs Model Specific Explanations")]),e._v(" "),a("li",[e._v("Data Modality Specific vs Data Modality Agnostic")]),e._v(" "),a("li",[e._v("Ad-Hoc vs Post-Hoc Explanations\n分类\n•局部解释vs全局解释\n•模型不可知vs特定于模型的解释\n• 数据模态特定vs数据模态不可知\n• 即时性和事后性解释")])]),e._v(" "),a("h2",{attrs:{id:"_3-preprocessing-of-ecg-signal-心电信号预处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-preprocessing-of-ecg-signal-心电信号预处理"}},[e._v("#")]),e._v(" 3. Preprocessing of ECG Signal 心电信号预处理")]),e._v(" "),a("h2",{attrs:{id:"_4-explainability-use-case-用例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-explainability-use-case-用例"}},[e._v("#")]),e._v(" 4. Explainability Use-Case 用例")]),e._v(" "),a("h2",{attrs:{id:"_5-local-interpretable-model-agnostic-explanations-lime-局部可解释模型-不可知解释-lime"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-local-interpretable-model-agnostic-explanations-lime-局部可解释模型-不可知解释-lime"}},[e._v("#")]),e._v(" 5.Local Interpretable Model -Agnostic Explanations(LIME) 局部可解释模型-不可知解释(LIME)")]),e._v(" "),a("h2",{attrs:{id:"_6-shapley-additive-explanations-沙普利加性解释"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-shapley-additive-explanations-沙普利加性解释"}},[e._v("#")]),e._v(" 6. Shapley Additive Explanations 沙普利加性解释")])])}),[],!1,null,null,null);a.default=n.exports}}]);