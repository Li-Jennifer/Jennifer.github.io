(window.webpackJsonp=window.webpackJsonp||[]).push([[96],{524:function(s,a,t){"use strict";t.r(a);var e=t(6),r=Object(e.a)({},(function(){var s=this,a=s._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p",[s._v("Report on your feature engineering pipeline, the classifier used to evaluate performance,\nand the performance as mean and standard deviation of accuracy, sensitivity and specificity across folds.\nGive evidence for why your strategy is better than others.")]),s._v(" "),a("h2",{attrs:{id:"_1-introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-introduction"}},[s._v("#")]),s._v(" 1.Introduction")]),s._v(" "),a("p",[s._v("Introduction to the case study\nClear statement of predictive/exploratory question")]),s._v(" "),a("p",[s._v("本组实验是为了根据脑电图(EEG)数据预测神经性疼痛嵴髓损伤(SCI)患者的中枢神经系统。通过实验对比选择特征工程，再结合分类器，后优化预测的准确性，最后得出最好的解决方案。")]),s._v(" "),a("h2",{attrs:{id:"_2-methods"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-methods"}},[s._v("#")]),s._v(" 2.Methods")]),s._v(" "),a("p",[s._v("Details of the methods being used in the study i.e. main idea, important parameters to tune"),a("br"),s._v("\n在选择特征工程上，目前有三种方式，分别是filtering，wrapper和embedding，我们会依次在这些特征工程上做实验对比，选取相对较好的特征工程。\n在选择器上，我们选择的是SVM，KNN和RFC来做实验。")]),s._v(" "),a("h3",{attrs:{id:"_2-1-filtering-classifier"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-filtering-classifier"}},[s._v("#")]),s._v(" 2.1 Filtering + Classifier")]),s._v(" "),a("p",[s._v("filtering算法的基本思想是根据每个特征，算出对应的信息量，从大到小排序，得到最靠前的特征。它的优点是复杂度低。\n其基本算法有Pearson相关系数，卡方验证，互信息和最大信息系数，距离相关系数和方差选择法。\n其中方差选择法的思想是计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征，重要参数是\n卡方的思想是，重要参数是\n所以，本组选取方差和卡方进行实验，实验过程如下。")]),s._v(" "),a("h4",{attrs:{id:"_1-方差和卡方对比-基于svm-score"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-方差和卡方对比-基于svm-score"}},[s._v("#")]),s._v(" （1）方差和卡方对比，基于SVM （score）")]),s._v(" "),a("h4",{attrs:{id:"_2-方差基于svm和knn-score"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-方差基于svm和knn-score"}},[s._v("#")]),s._v(" （2）方差基于SVM和KNN （score）")]),s._v(" "),a("h4",{attrs:{id:"_3-svm-rfc-基于卡方"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-svm-rfc-基于卡方"}},[s._v("#")]),s._v(" （3）SVM + RFC 基于卡方")]),s._v(" "),a("h3",{attrs:{id:"_2-2-wrapper-classifier"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-wrapper-classifier"}},[s._v("#")]),s._v(" 2.2 Wrapper + Classifier")]),s._v(" "),a("p",[s._v("svm和随机森林\nsvm比较")]),s._v(" "),a("h3",{attrs:{id:"_2-3-embedding-classifier"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-embedding-classifier"}},[s._v("#")]),s._v(" 2.3 Embedding + Classifier")]),s._v(" "),a("p",[s._v("嵌入\nrfc+svm")]),s._v(" "),a("h2",{attrs:{id:"_3-results"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-results"}},[s._v("#")]),s._v(" 3.Results")]),s._v(" "),a("p",[s._v("Details of numerical experiment setup i.e. training, test, validation and etc\nExperiment results i.e. performance metrics in figures and tables")]),s._v(" "),a("h3",{attrs:{id:"_3-1-evaluation-mean-and-standard-deviation-of-accuracy-sensitivity-and-specificity-across-folds"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-evaluation-mean-and-standard-deviation-of-accuracy-sensitivity-and-specificity-across-folds"}},[s._v("#")]),s._v(" 3.1 Evaluation （ mean and standard deviation of accuracy, sensitivity and specificity across folds. ）")]),s._v(" "),a("h2",{attrs:{id:"_4-discussion"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-discussion"}},[s._v("#")]),s._v(" 4.Discussion")]),s._v(" "),a("p",[s._v("What conclusion can you draw from the results, and why.")])])}),[],!1,null,null,null);a.default=r.exports}}]);